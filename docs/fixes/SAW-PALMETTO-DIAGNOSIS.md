# Diagn√≥stico Completo: "saw palmetto" 404 Error

**Fecha:** November 22, 2024  
**Status:** üî¥ Problema identificado - Timeout en content-enricher Lambda

---

## üîç S√≠ntomas

Usuario busca "saw palmetto" y recibe:
```
‚ùå No pudimos encontrar informaci√≥n cient√≠fica suficiente sobre "saw palmetto"
```

---

## üìä Traza Completa

### 1. Frontend ‚Üí Vercel API Route
```
Request: POST /api/portal/enrich
Body: { supplementName: "saw palmetto" }
Timeout: 30 segundos (Vercel limit)
```

### 2. API Route ‚Üí Abbreviation Expander (NUEVO C√ìDIGO)
```
‚úÖ SUCCESS
Duration: 1.8s (primera llamada con cache write)
Result: ["saw palmetto", "serenoa repens"]
Cache: 4027 tokens escritos
```

**Nota:** El c√≥digo nuevo de Prompt Caching funciona perfectamente ‚úÖ

### 3. API Route ‚Üí Studies Fetcher Lambda
```
‚úÖ SUCCESS
Duration: 2.1s
Studies Found: 10
Query: (saw[tiab] AND palmetto[tiab]) AND ("randomized controlled trial"[Publication Type] OR "meta-analysis"[Publication Type] OR "systematic review"[Publication Type]) AND 2010:2025[Date - Publication] AND "humans"[MeSH Terms]
```

**Logs:**
```json
{
  "event": "STUDIES_FETCH_SUCCESS",
  "supplementName": "saw palmetto",
  "studiesFound": 10,
  "duration": 2104,
  "timestamp": "2025-11-22T17:19:23.893Z"
}
```

### 4. API Route ‚Üí Content Enricher Lambda
```
‚ùå TIMEOUT
Duration: 119 segundos (2 minutos!)
Model: Claude 3.5 Sonnet
Tokens: 15,685 total (11,674 input + 4,011 output)
```

**Logs:**
```json
{
  "operation": "ConverseAPICall",
  "supplementId": "saw palmetto",
  "modelId": "anthropic.claude-3-5-sonnet-20240620-v1:0",
  "timestamp": "2025-11-22T17:19:24.925Z"
}

{
  "operation": "ConverseAPIResponse",
  "duration": 119789,  // ‚Üê 119 SEGUNDOS!
  "tokensUsed": 15685,
  "timestamp": "2025-11-22T17:21:24.713Z"
}
```

### 5. Vercel Timeout
```
‚ùå 504 Gateway Timeout
Duration: 31.5 segundos
Error: "Endpoint request timed out"
```

**Response:**
```json
{
  "success": false,
  "error": "Failed to enrich content",
  "details": "{\"message\": \"Endpoint request timed out\"}"
}
```

---

## üéØ Root Cause

**Content Enricher Lambda tarda 2 minutos** en generar contenido con Claude 3.5 Sonnet, pero:
- Vercel Free tier: 10s timeout
- Vercel Pro tier: 60s timeout  
- Vercel Enterprise: 900s timeout

**Nuestro caso:** Probablemente Pro tier (60s), pero el Lambda tarda 119s.

---

## ‚úÖ Lo que S√ç funciona

1. ‚úÖ **Abbreviation Expander** - Prompt caching funcionando perfectamente
2. ‚úÖ **Studies Fetcher** - Encuentra 10 estudios en 2 segundos
3. ‚úÖ **Scientific Names** - Sugiere "serenoa repens" correctamente
4. ‚úÖ **PubMed Search** - 380 estudios disponibles

---

## ‚ùå Lo que NO funciona

1. ‚ùå **Content Enricher Lambda** - Tarda 119 segundos (2 minutos)
2. ‚ùå **Vercel Timeout** - Solo permite 60 segundos m√°ximo
3. ‚ùå **User Experience** - Usuario recibe 504 timeout

---

## üîß Soluciones Propuestas

### Opci√≥n 1: Optimizar Content Enricher (RECOMENDADO)
**Objetivo:** Reducir tiempo de 119s a <30s

**Acciones:**
1. Implementar Prompt Caching en content-enricher
   - System prompt cacheado (>2048 tokens)
   - Reducir latencia de 119s a ~20-30s en cache hits
   
2. Reducir tama√±o del prompt
   - Actualmente: 11,674 input tokens
   - Objetivo: <5,000 input tokens
   - M√©todo: Resumir estudios antes de enviar a Claude

3. Usar modelo m√°s r√°pido
   - Actual: Claude 3.5 Sonnet (lento pero preciso)
   - Alternativa: Claude 3.5 Haiku (r√°pido pero menos preciso)
   - Compromiso: Claude 3 Haiku para primera generaci√≥n, Sonnet para refinamiento

**Estimaci√≥n:** 2-3 horas de trabajo

### Opci√≥n 2: Arquitectura As√≠ncrona
**Objetivo:** Retornar inmediatamente, procesar en background

**Flujo:**
```
1. User request ‚Üí API Route
2. API Route ‚Üí Start async job
3. Return 202 Accepted + job ID
4. Frontend polls for completion
5. Lambda completes ‚Üí Update DynamoDB
6. Frontend retrieves result
```

**Pros:**
- No timeout issues
- Better UX con loading states
- Escalable

**Cons:**
- M√°s complejo
- Requiere polling o WebSockets
- Cambios en frontend

**Estimaci√≥n:** 4-6 horas de trabajo

### Opci√≥n 3: Aumentar Vercel Tier
**Objetivo:** Permitir m√°s tiempo de ejecuci√≥n

**Requisitos:**
- Vercel Enterprise: 900s timeout
- Costo: ~$150/mes

**Pros:**
- Sin cambios de c√≥digo
- Soluci√≥n inmediata

**Cons:**
- Caro
- No resuelve el problema de fondo
- Mala UX (2 minutos de espera)

**Recomendaci√≥n:** ‚ùå No recomendado

---

## üìù Recomendaci√≥n Final

**Implementar Opci√≥n 1: Optimizar Content Enricher**

**Prioridad 1 - Quick Win (30 min):**
1. Reducir maxTokens de 8192 a 4096
2. Resumir estudios antes de enviar (solo abstract + conclusi√≥n)
3. Objetivo: Reducir de 11,674 a ~5,000 input tokens

**Prioridad 2 - Prompt Caching (1-2 horas):**
1. Implementar system prompt cacheado en content-enricher
2. Similar a lo que hicimos en abbreviation-expander
3. Objetivo: 90% reducci√≥n en latencia en cache hits

**Prioridad 3 - Modelo H√≠brido (1 hora):**
1. Usar Claude 3.5 Haiku para generaci√≥n inicial
2. Cache el resultado
3. Usar Sonnet solo si se requiere refinamiento

**Resultado esperado:**
- Primera llamada: 30-40s (dentro del timeout de Vercel)
- Llamadas siguientes: 5-10s (con cache)
- Costo: 70-80% reducci√≥n

---

## üß™ Testing

### Validar que el problema persiste:
```bash
npx tsx scripts/test-saw-palmetto-production.ts
```

### Despu√©s de implementar fix:
```bash
# Test 1: Primera llamada (sin cache)
time curl -X POST https://suplementia.vercel.app/api/portal/enrich \
  -H "Content-Type: application/json" \
  -d '{"supplementName":"saw palmetto"}'

# Test 2: Segunda llamada (con cache)
time curl -X POST https://suplementia.vercel.app/api/portal/enrich \
  -H "Content-Type: application/json" \
  -d '{"supplementName":"saw palmetto"}'
```

**Objetivo:** Ambas llamadas deben completar en <30s

---

## üìö Referencias

1. **Vercel Timeouts**
   - https://vercel.com/docs/functions/serverless-functions/runtimes#max-duration
   - Free: 10s, Pro: 60s, Enterprise: 900s

2. **AWS Bedrock Prompt Caching**
   - https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-caching.html
   - 90% cost reduction, 75-90% latency reduction

3. **Claude Model Comparison**
   - Haiku: Fast, cheap, good for simple tasks
   - Sonnet: Balanced, best for most use cases
   - Opus: Slow, expensive, best quality

---

**Status:** üî¥ Bloqueado por timeout  
**C√≥digo nuevo:** ‚úÖ Funcionando correctamente  
**Pr√≥ximo paso:** Optimizar content-enricher Lambda  
**ETA:** 2-3 horas de trabajo

