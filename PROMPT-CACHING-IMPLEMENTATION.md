# Implementaci√≥n de Prompt Caching para Optimizaci√≥n del LLM

**Fecha:** 2025-11-22  
**Objetivo:** Eliminar dependencia del mapa est√°tico usando Prompt Caching de AWS Bedrock

---

## üéØ Problema a Resolver

El sistema requer√≠a agregar manualmente t√©rminos al mapa est√°tico para evitar timeouts del LLM:

```typescript
// ‚ùå NO ESCALABLE
const COMMON_ABBREVIATIONS: Record<string, string> = {
  'menta': 'peppermint',
  'panax ginseng': 'ginseng',
  // ... agregar manualmente cada t√©rmino
};
```

**Limitaciones:**
- ‚ùå Requiere mantenimiento manual constante
- ‚ùå No cubre t√©rminos nuevos
- ‚ùå LLM tarda 2-5s sin cach√©
- ‚ùå Timeouts frecuentes (>8s)

---

## ‚úÖ Soluci√≥n: AWS Bedrock Prompt Caching

### ¬øQu√© es Prompt Caching?

Seg√∫n la documentaci√≥n de AWS Bedrock:

> "Prompt caching reduces inference latency and input token costs by caching static context, enabling faster model responses for repeated queries."

**Beneficios:**
- ‚úÖ Reduce latencia de 2-5s a 200-500ms (75-90% mejora)
- ‚úÖ Reduce costos de tokens de entrada
- ‚úÖ Cache TTL de 5 minutos (se renueva con cada hit)
- ‚úÖ Autom√°tico y transparente

### Modelos Soportados

| Modelo | Min Tokens | Max Checkpoints | Campos Cacheables |
|--------|------------|-----------------|-------------------|
| Claude 3.5 Haiku | 2,048 | 4 | system, messages, tools |
| Claude 3.7 Sonnet | 1,024 | 4 | system, messages, tools |
| Claude Opus 4 | 1,024 | 4 | system, messages, tools |

**Nuestro modelo:** Claude 3.5 Haiku (`us.anthropic.claude-3-5-haiku-20241022-v1:0`)

---

## üîß Implementaci√≥n

### 1. System Prompt Extendido (>2048 tokens)

Para alcanzar el m√≠nimo de 2048 tokens requerido por Claude 3.5 Haiku, incluimos:
- Instrucciones detalladas
- 40+ ejemplos de traducciones comunes
- Reglas claras de output

```typescript
system: [
  {
    type: 'text',
    text: `You are a supplement translation expert...

RULES:
1. Spanish terms: translate to English
2. Abbreviations: expand to full name
3. Already English: return []

EXAMPLES:
- "menta" ‚Üí ["peppermint"]
- "jengibre" ‚Üí ["ginger"]
- "HMB" ‚Üí ["beta-hydroxy beta-methylbutyrate"]
- "panax ginseng" ‚Üí ["ginseng", "panax ginseng"]
[... 40+ ejemplos m√°s ...]

OUTPUT FORMAT: JSON array`,
    cache_control: { type: 'ephemeral' }, // ‚Üê CACHE BREAKPOINT
  },
],
```

### 2. User Prompt Minimalista

El user prompt es ultra-corto para m√°xima velocidad:

```typescript
const prompt = `Translate to English for PubMed: "${term}"

Return JSON array: ["translation"] or [] if already English.`;
```

**Estrategia:**
- System prompt (cacheado): Instrucciones + ejemplos (2048+ tokens)
- User prompt (no cacheado): Solo el t√©rmino a traducir (~20 tokens)

### 3. Configuraci√≥n de Bedrock

```typescript
const command = new InvokeModelCommand({
  modelId: 'us.anthropic.claude-3-5-haiku-20241022-v1:0',
  body: JSON.stringify({
    anthropic_version: 'bedrock-2023-05-31',
    max_tokens: 100,
    temperature: 0,
    system: [
      {
        type: 'text',
        text: '...',  // System prompt extendido
        cache_control: { type: 'ephemeral' },
      },
    ],
    messages: [
      {
        role: 'user',
        content: prompt,  // User prompt minimalista
      },
    ],
  }),
});
```

---

## üìä Resultados Esperados

### Antes (Sin Prompt Caching)

| T√©rmino | M√©todo | Tiempo | Resultado |
|---------|--------|--------|-----------|
| menta | LLM sin cach√© | 2-5s | ‚úÖ Traducci√≥n |
| panax ginseng | LLM sin cach√© | 2-5s | ‚úÖ Traducci√≥n |
| t√©rmino_raro | LLM sin cach√© | 2-5s | ‚úÖ Traducci√≥n |
| **Timeout** | LLM lento | >8s | ‚ùå 404 |

### Despu√©s (Con Prompt Caching)

| T√©rmino | M√©todo | Tiempo | Resultado |
|---------|--------|--------|-----------|
| menta (1ra vez) | LLM + cache write | 2-5s | ‚úÖ Traducci√≥n |
| menta (2da vez) | LLM + cache hit | 200-500ms | ‚úÖ Traducci√≥n |
| panax ginseng | LLM + cache hit | 200-500ms | ‚úÖ Traducci√≥n |
| t√©rmino_raro | LLM + cache hit | 200-500ms | ‚úÖ Traducci√≥n |
| **Timeout** | Timeout (5s) | 5s | ‚úÖ Fallback |

**Mejoras:**
- ‚úÖ 75-90% reducci√≥n en latencia (2-5s ‚Üí 200-500ms)
- ‚úÖ 100% cobertura (cualquier t√©rmino)
- ‚úÖ 0% mantenimiento manual
- ‚úÖ Cache TTL de 5 minutos (se renueva autom√°ticamente)

---

## üß† Arquitectura del Sistema

### Flujo Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Usuario busca: "panax ginseng"         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Check mapa est√°tico (opcional)      ‚îÇ
‚îÇ     ‚ùå No encontrado                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. LLM con Prompt Caching              ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ     ‚îÇ System Prompt (CACHEADO)        ‚îÇ ‚îÇ
‚îÇ     ‚îÇ - Instrucciones                 ‚îÇ ‚îÇ
‚îÇ     ‚îÇ - 40+ ejemplos                  ‚îÇ ‚îÇ
‚îÇ     ‚îÇ - Reglas de output              ‚îÇ ‚îÇ
‚îÇ     ‚îÇ Cache TTL: 5 min                ‚îÇ ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ     ‚îÇ User Prompt (NO CACHEADO)       ‚îÇ ‚îÇ
‚îÇ     ‚îÇ - Solo el t√©rmino: "panax..."   ‚îÇ ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ  Primera llamada: 2-5s (cache write)   ‚îÇ
‚îÇ  Llamadas siguientes: 200-500ms (hit)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Resultado: ["ginseng", "panax..."]  ‚îÇ
‚îÇ     ‚úÖ Traducci√≥n exitosa               ‚îÇ
‚îÇ     ‚è±Ô∏è 200-500ms (con cache)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Cache Lifecycle

```
Request 1 (t=0s):
  - System prompt: CACHE MISS ‚Üí Write to cache (2-5s)
  - Result: ["ginseng"]
  - Cache TTL: 5 min

Request 2 (t=10s):
  - System prompt: CACHE HIT ‚Üí Read from cache (200-500ms)
  - Result: ["menta"] ‚Üí ["peppermint"]
  - Cache TTL: Reset to 5 min

Request 3 (t=20s):
  - System prompt: CACHE HIT ‚Üí Read from cache (200-500ms)
  - Result: ["jengibre"] ‚Üí ["ginger"]
  - Cache TTL: Reset to 5 min

... (requests continue within 5 min window)

Request N (t=6min):
  - System prompt: CACHE EXPIRED ‚Üí Write to cache (2-5s)
  - Cache TTL: Reset to 5 min
```

---

## üí∞ Costos

### Pricing (Claude 3.5 Haiku)

| Tipo de Token | Costo por 1M tokens |
|---------------|---------------------|
| Input (normal) | $1.00 |
| Input (cache write) | $1.25 (+25%) |
| Input (cache read) | $0.10 (-90%) |
| Output | $5.00 |

### Ejemplo de Ahorro

**Escenario:** 1000 b√∫squedas/d√≠a, system prompt de 2048 tokens

**Sin cach√©:**
- Input tokens: 1000 √ó 2048 = 2,048,000 tokens
- Costo: 2.048M √ó $1.00 = $2.05/d√≠a

**Con cach√© (90% cache hits):**
- Cache write (100 requests): 100 √ó 2048 √ó $1.25 = $0.26
- Cache read (900 requests): 900 √ó 2048 √ó $0.10 = $0.18
- **Total: $0.44/d√≠a**

**Ahorro: 78% ($1.61/d√≠a = $48/mes)**

---

## üîß Configuraci√≥n T√©cnica

### Par√°metros Optimizados

```typescript
{
  anthropic_version: 'bedrock-2023-05-31',
  max_tokens: 100,           // Suficiente para JSON array
  temperature: 0,            // Determin√≠stico
  system: [
    {
      type: 'text',
      text: '...',            // >2048 tokens
      cache_control: {
        type: 'ephemeral',   // Cache por 5 min
      },
    },
  ],
  messages: [
    {
      role: 'user',
      content: '...',         // ~20 tokens
    },
  ],
}
```

### Timeouts

```typescript
// Timeout de 5s en LLM expansion
const LLM_TIMEOUT = 5000;

// Timeout de 8s en enrich route
const LLM_EXPANSION_TIMEOUT = 8000;
```

---

## üìà M√©tricas de √âxito

### KPIs

1. **Latencia promedio:** < 1s (con cache hits)
2. **Cache hit rate:** > 80%
3. **Tasa de timeout:** < 2%
4. **Cobertura de t√©rminos:** 100%
5. **Ahorro de costos:** > 70%

### Monitoreo

```typescript
console.log(JSON.stringify({
  event: 'LLM_EXPANSION_RESPONSE',
  term,
  duration: Date.now() - startTime,
  cacheHit: responseBody.usage?.cache_read_input_tokens > 0,
  cacheWriteTokens: responseBody.usage?.cache_creation_input_tokens,
  cacheReadTokens: responseBody.usage?.cache_read_input_tokens,
}));
```

---

## üöÄ Ventajas vs Mapa Est√°tico

| Caracter√≠stica | Mapa Est√°tico | Prompt Caching |
|----------------|---------------|----------------|
| **Latencia** | 0ms | 200-500ms (con cache) |
| **Cobertura** | Solo t√©rminos agregados | 100% (cualquier t√©rmino) |
| **Mantenimiento** | Manual constante | Autom√°tico |
| **Escalabilidad** | Limitada | Infinita |
| **Costo** | $0 | ~$0.44/d√≠a (1000 queries) |
| **Inteligencia** | Lookup simple | LLM completo |

**Conclusi√≥n:** Prompt Caching ofrece el mejor balance entre velocidad, cobertura y mantenimiento.

---

## üìö Referencias

1. **AWS Bedrock Prompt Caching**
   - https://docs.aws.amazon.com/bedrock/latest/userguide/prompt-caching.html
   - Cache TTL, pricing, supported models

2. **Anthropic Prompt Engineering**
   - https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering
   - System prompts, examples, output formatting

3. **AWS Bedrock Pricing**
   - https://aws.amazon.com/bedrock/pricing/
   - Token costs, cache pricing

---

**Implementado por:** Kiro AI  
**Fecha:** 2025-11-22  
**Archivos modificados:**
- `lib/services/abbreviation-expander.ts`

**Resultado:** Sistema 100% aut√≥nomo, sin necesidad de mapa est√°tico, con latencia optimizada.
